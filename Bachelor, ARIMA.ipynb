{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import warnings\n",
    "import pmdarima as pm\n",
    "import random\n",
    "random.seed(10)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#https://par.nsf.gov/servlets/purl/10186768#:~:text=%E2%80%93%20Compare%20the%20performance%20of%20LSTM,indicating%20the%20superiority%20of%20LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_df = pd.read_csv('data/AIRLINE_PASSENGERS.csv', parse_dates=['Date'])\n",
    "alcohol_df = pd.read_csv('data/ALCOHOL_SALES.csv', parse_dates=['Date'])\n",
    "beer_df = pd.read_csv('data/AUS_BEER_PRODUCTION.csv', parse_dates=['Date'])\n",
    "electric_df = pd.read_csv('data/ELECTRIC_PRODUCTION.csv', parse_dates=['Date'])\n",
    "minTemp_df = pd.read_csv('data/MIN_TEMP.csv', parse_dates=['Date'])\n",
    "gdp_df = pd.read_csv('data/NOR_GDP.csv', parse_dates=['Date'])\n",
    "#population_df = pd.read_csv('data/POPULATION.csv', parse_dates=['Date'])\n",
    "sunspots_df = pd.read_csv('data/SUNSPOTS.csv', parse_dates=['Date'])\n",
    "SP_df = pd.read_csv('data/SP.csv', parse_dates=['Date'])\n",
    "yahoo_df = pd.read_csv('data/YAHOO.csv', parse_dates=['Date'])\n",
    "tesla_df = pd.read_csv('data/TESLA.csv', parse_dates=['Date'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_name(dfs,names):\n",
    "    for ind, df in enumerate(dfs):\n",
    "        df.name = names[ind]\n",
    "    return dfs\n",
    "name_list = ['passengers_df', 'alcohol_df', 'beer_df', \n",
    "             'electric_df', 'minTemp_df', 'gdp_df', 'sunspots_df','SP_df', 'yahoo_df', 'tesla_df']\n",
    "\n",
    "\n",
    "dfs_list = []\n",
    "dfs_list.append(passengers_df)\n",
    "dfs_list.append(alcohol_df)\n",
    "dfs_list.append(beer_df)\n",
    "dfs_list.append(electric_df)\n",
    "dfs_list.append(minTemp_df)\n",
    "dfs_list.append(gdp_df)\n",
    "dfs_list.append(sunspots_df)\n",
    "dfs_list.append(SP_df)\n",
    "dfs_list.append(yahoo_df)\n",
    "dfs_list.append(tesla_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dfs_list = set_name(dfs_list, name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(dfs):\n",
    "    transformed = []\n",
    "    lambda_list = []\n",
    "    for df in dfs:\n",
    "        col_transformed = boxcox(df[df.columns[1]], 0)\n",
    "        col_transformed = pd.DataFrame({'Date': df[df.columns[0]], f'{df.columns[1]}': col_transformed})\n",
    "        transformed.append(col_transformed)\n",
    "        lambda_list.append(0) \n",
    "    transformed = set_name(transformed, name_list)\n",
    "    return transformed, lambda_list\n",
    "\n",
    "def inverse_transform(transformed_df, lambda_):\n",
    "    inv_df = inv_boxcox(transformed_df, lambda_)\n",
    "    return inv_df\n",
    "\n",
    "log_transformed_list, best_lambdas = log_transform(dfs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc724d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(actual, pred):\n",
    "    return np.mean(np.abs((actual - pred)/actual))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df142b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m(data):\n",
    "    #setting m\n",
    "    days = (data[data.columns[0]][1] - data[data.columns[0]][0]).days\n",
    "    if days >= 1 and days <= 4:\n",
    "        m = 7\n",
    "    elif days <= 31 and days >= 28:\n",
    "        m = 12\n",
    "    elif days == 7:\n",
    "        m = 52\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, ratio, nr_of_forecasts):\n",
    "   \n",
    "     \n",
    "    split_range = int(len(df)* ratio)\n",
    "    train, test, forecasts = np.array(df[df.columns[1]][0:split_range]), np.array(df[df.columns[1]][split_range:len(df)-nr_of_forecasts]), np.array(df[df.columns[1]][len(df)-nr_of_forecasts:len(df)]) \n",
    "    return train, test, forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b47b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdq_values(df, max_p, max_q, max_P = None, max_Q = None, which_model = None):\n",
    "    if which_model == \"ARIMA\":\n",
    "        model = pm.auto_arima(df[df.columns[1]], information_criterion= 'aic', max_p = max_p, max_q = max_q,  MAX_P = 0, MAX_D= 0, MAX_Q = 0, stepwise= True )\n",
    "        p = model.get_params()['order'][0]\n",
    "        d = model.get_params()['order'][1]\n",
    "        q = model.get_params()['order'][2]\n",
    "        return p, d, q\n",
    "    else:\n",
    "        model = pm.auto_arima(df[df.columns[1]], information_criterion= 'aic', max_p = max_p, max_q = max_q,  max_P = max_P, max_D= 2,  max_Q = max_Q, m= get_m(df),stepwise= False )\n",
    "        p = model.get_params()['order'][0]\n",
    "        d = model.get_params()['order'][1]\n",
    "        q = model.get_params()['order'][2]\n",
    "        P = model.get_params()['seasonal_order'][0]\n",
    "        D = model.get_params()['seasonal_order'][1]\n",
    "        Q = model.get_params()['seasonal_order'][2]\n",
    "        m = model.get_params()['seasonal_order'][3]\n",
    "        return p, d, q, P, D, Q, m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ddb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arima_accuracy(df,best_lambda, fcs_nr_list, max_p, max_q, max_P = None, max_Q = None, which_model = None):\n",
    "    \n",
    "    \n",
    "    training, test, all_forecasts = split_train_test(df, ratio = 0.75, nr_of_forecasts= 10)\n",
    "    training_fit = training\n",
    "    \n",
    "    if which_model == \"ARIMA\":\n",
    "        p, d, q = get_pdq_values(df.iloc[:-10], max_p, max_q, which_model=\"ARIMA\")\n",
    "        model = ARIMA(training, order = (p, d, q))\n",
    "    else:\n",
    "        p, d, q, P, D, Q, m = get_pdq_values(df.iloc[:-10], max_p, max_q, max_P, max_Q, which_model= \"SARIMA\")\n",
    "        print(p, d, q, P, D, Q, m)\n",
    "        model = SARIMAX(training, order=(p, d, q), seasonal_order=(P, D, Q, m))\n",
    "    model_fit = model.fit()\n",
    "        \n",
    "    training_fcs = model_fit.predict(dynamic = False)\n",
    "    training, training_fcs = inverse_transform(training, best_lambda), inverse_transform(training_fcs, best_lambda)\n",
    "    train_rmse = (mean_squared_error(training, training_fcs))**0.5\n",
    "    train_mape = get_mape(training, training_fcs)\n",
    "   \n",
    "    print(f'train rmse: {train_rmse}')\n",
    "    print(f'train mape: {train_mape}')\n",
    "    \n",
    "    test_fcs = np.array([])\n",
    "    for i in range(len(test)):\n",
    "        if which_model == \"ARIMA\":\n",
    "            model = ARIMA(training_fit, order = (p, d, q))\n",
    "        else:\n",
    "            model = SARIMAX(training_fit, order = (p, d, q), seasonal_order = (P, D, Q,m))\n",
    "        model_fit = model.fit()\n",
    "        single_fc = model_fit.forecast()\n",
    "        \n",
    "        test_fcs = np.append(test_fcs,single_fc)\n",
    "        training_fit = np.append(training_fit, test[i])\n",
    "        \n",
    "        \n",
    "      \n",
    "        \n",
    "   \n",
    "    test, test_fcs = inverse_transform(test, best_lambda), inverse_transform(test_fcs, best_lambda)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #plt.plot(training)\n",
    "    #plt.plot(training_fcs)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    test_rmse = (mean_squared_error(test,test_fcs))**0.5\n",
    "    test_mape = get_mape(test, test_fcs)\n",
    "    #plt.plot(test)\n",
    "    #plt.plot(test_fcs)\n",
    "    #plt.show()\n",
    "    print(f'test rmse: {test_rmse}')\n",
    "    print(f'test mape: {test_mape}')\n",
    "    \n",
    "    forecasts_rmse_list = []\n",
    "    forecasts_mape_list = []\n",
    "    for fcs in fcs_nr_list:\n",
    "        forecasts_predictions = model_fit.forecast(steps = fcs)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        forecasts_rmse = np.round((mean_squared_error(inverse_transform(all_forecasts, best_lambda)[0:fcs],inverse_transform(forecasts_predictions, best_lambda)))**0.5, 4)\n",
    "        forecasts_mape = np.round(get_mape(inverse_transform(all_forecasts, best_lambda)[0:fcs],inverse_transform(forecasts_predictions, best_lambda)), 4)\n",
    "        \n",
    "        \n",
    "        \n",
    "        forecasts_rmse_list.append(forecasts_rmse)\n",
    "        forecasts_mape_list.append(forecasts_mape)\n",
    "    #plt.plot(forecasts, marker = 'o')\n",
    "    #plt.plot(forecasts_predictions, marker = 'x')\n",
    "    #plt.show()\n",
    "    \n",
    "    print(f'forecasts rmse: {forecasts_rmse_list}')\n",
    "    print(f'forecasts mape: {forecasts_mape_list}')\n",
    "    return np.round(train_rmse, 4), np.round(train_mape, 4), np.round(test_rmse, 4), np.round(test_mape, 4), forecasts_rmse_list, forecasts_mape_list\n",
    "    \n",
    "    \n",
    "\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cv(filepath, train_rmse, train_mape, test_rmse, test_mape, fc_rmse, fc_mape):\n",
    "    \n",
    "    df = pd.DataFrame({'Data': name_list, 'Train RMSE': train_rmse,'Train MAPE': train_mape,\n",
    "                       'Test RMSE': test_rmse, 'Test MAPE': test_mape, '1-step RMSE': [x[0] for x in fc_rmse],\n",
    "                       '3-step RMSE': [x[1] for x in fc_rmse], '5-step RMSE': [x[2] for x in fc_rmse],\n",
    "                        '10-step RMSE': [x[3] for x in fc_rmse],'1-step MAPE': [x[0] for x in fc_mape],\n",
    "                       '3-step MAPE': [x[1] for x in fc_mape],'5-step MAPE': [x[2] for x in fc_mape],\n",
    "                       '10-step MAPE': [x[3] for x in fc_mape] })\n",
    "    df.to_csv(filepath, index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1e2e0",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_list, train_mape_list, test_rmse_list, test_mape_list, fc_rmse_list_list,fc_mape_list_list  = [], [], [], [], [], []\n",
    "nr_of_forecasts_list = [1, 3, 5, 10]\n",
    "for ind, df in enumerate(log_transformed_list):\n",
    "    print(df.name)\n",
    "    train_rmse, train_mape, test_rmse, test_mape, fc_rmse_list, fc_mape_list = get_arima_accuracy(df,best_lambda = best_lambdas[ind],fcs_nr_list = nr_of_forecasts_list, max_p = 5, max_q= 5, which_model = \"ARIMA\")\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    train_mape_list.append(train_mape)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    test_mape_list.append(test_mape)\n",
    "    fc_rmse_list_list.append(fc_rmse_list)\n",
    "    fc_mape_list_list.append(fc_mape_list)\n",
    "results = save_cv(\"results/ARIMA_results.csv\", train_rmse_list, train_mape_list, test_rmse_list, test_mape_list, fc_rmse_list_list, fc_mape_list_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdb753",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a0a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_list, train_mape_list, test_rmse_list, test_mape_list, fc_rmse_list_list, fc_mape_list_list = [], [], [], [], [], []\n",
    "nr_of_forecasts = [1, 3, 5, 10]\n",
    "log_transformed_list, best_lambdas = log_transform(dfs_list)\n",
    "for ind, df in enumerate(log_transformed_list):\n",
    "    print(df.name)\n",
    "    train_rmse, train_mape, test_rmse, test_mape, fc_rmse_list, fc_mape_list = get_arima_accuracy(df,best_lambda = best_lambdas[0],fcs_nr_list= nr_of_forecasts, max_p = 5, max_q= 5, max_Q = 5, max_P = 5, which_model = 'SARIMA')\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    train_mape_list.append(train_mape)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    test_mape_list.append(test_mape)\n",
    "    fc_rmse_list_list.append(fc_rmse_list)\n",
    "    fc_mape_list_list.append(fc_mape_list)\n",
    "results = save_cv(\"results/SARIMA_results.csv\", train_rmse_list, train_mape_list, test_rmse_list, test_mape_list, fc_rmse_list_list, fc_mape_list_list)\n",
    "\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd0b1d608bd0e5024644dae2cdbcee13271296bd49f5e48df2e59ce3d0ae5b90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
