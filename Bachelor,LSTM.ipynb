{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "# tensorflow 2.6, numpy 1.95 needed \n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_df = pd.read_csv('data/AIRLINE_PASSENGERS.csv', parse_dates=['Date'])\n",
    "alcohol_df = pd.read_csv('data/ALCOHOL_SALES.csv', parse_dates=['Date'])\n",
    "beer_df = pd.read_csv('data/AUS_BEER_PRODUCTION.csv', parse_dates=['Date'])\n",
    "electric_df = pd.read_csv('data/ELECTRIC_PRODUCTION.csv', parse_dates=['Date'])\n",
    "minTemp_df = pd.read_csv('data/MIN_TEMP.csv', parse_dates=['Date'])\n",
    "gdp_df = pd.read_csv('data/NOR_GDP.csv', parse_dates=['Date'])\n",
    "#population_df = pd.read_csv('data/POPULATION.csv', parse_dates=['Date'])\n",
    "sunspots_df = pd.read_csv('data/SUNSPOTS.csv', parse_dates=['Date'])\n",
    "SP_df = pd.read_csv('data/SP.csv', parse_dates=['Date'])\n",
    "yahoo_df = pd.read_csv('data/YAHOO.csv', parse_dates=['Date'])\n",
    "tesla_df = pd.read_csv('data/TESLA.csv', parse_dates=['Date'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_name(dfs,names):\n",
    "    for ind, df in enumerate(dfs):\n",
    "        df.name = names[ind]\n",
    "    return dfs\n",
    "name_list = ['passengers_df', 'alcohol_df', 'beer_df', \n",
    "             'electric_df', 'minTemp_df', 'gdp_df', 'sunspots_df','SP_df', 'yahoo_df', 'tesla_df']\n",
    "\n",
    "\n",
    "dfs_list = []\n",
    "dfs_list.append(passengers_df)\n",
    "dfs_list.append(alcohol_df)\n",
    "dfs_list.append(beer_df)\n",
    "dfs_list.append(electric_df)\n",
    "dfs_list.append(minTemp_df)\n",
    "dfs_list.append(gdp_df)\n",
    "dfs_list.append(sunspots_df)\n",
    "dfs_list.append(SP_df)\n",
    "dfs_list.append(yahoo_df)\n",
    "dfs_list.append(tesla_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dfs_list = set_name(dfs_list, name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, ratio, nr_of_forecasts):\n",
    "    split_range = int(len(df)* ratio)\n",
    "    train, test, forecasts = df[0:split_range],df[split_range:len(df)-nr_of_forecasts], df[len(df)-nr_of_forecasts:len(df)]  \n",
    "    return train, test, forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(actual, pred):\n",
    "    return np.mean(np.abs((actual - pred)/actual))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(df, ratio, fcs_nr_list):\n",
    "\n",
    "    data = df[df.columns[1]].values.reshape(-1, 1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "    data_scaled = min_max_scaler.fit_transform(data)\n",
    "    data_scaled = timeseries_to_supervised(data_scaled).values\n",
    "\n",
    "    train, test, forecasts = split_train_test(data_scaled, ratio, nr_of_forecasts=10)\n",
    "\n",
    "    X_train, y_train = train[:, 0:-1], train[:, -1]\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 4, activation = 'relu', batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    for i in range(500):\n",
    "        model.fit(X_train, y_train, epochs= 1, batch_size=1, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    \n",
    "    #model.fit(X_train, y_train, epochs = 50, batch_size = 1, verbose =0, shuffle = False )\n",
    "    \n",
    "    train_forecasts = model.predict(X_train, batch_size=1)\n",
    "    \n",
    "    train_forecasts = np.ravel(min_max_scaler.inverse_transform(train_forecasts))\n",
    "    y_train = np.ravel(min_max_scaler.inverse_transform(y_train.reshape(-1, 1)))\n",
    "   \n",
    "    train_rmse = np.round((mean_squared_error(train_forecasts, y_train))**0.5, 4)\n",
    "    train_mape = np.round(get_mape(train_forecasts, y_train), 4)\n",
    "    \n",
    "    #plt.plot(y_train)\n",
    "    #plt.plot(train_forecasts)\n",
    "    #plt.show()\n",
    "    print(f'train rmse: {train_rmse}')\n",
    "    print(f'train mape: {train_mape}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, y_train = train[:, 0:-1], train[:, -1]\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    \n",
    "    test_fcs = np.array([])\n",
    "    for i in range(len(test)):\n",
    "        model.fit(X_train, y_train, epochs= 1, batch_size=1, verbose=0, shuffle=False)\n",
    "        \n",
    "        X_test, y_test = test[i, 0:-1], test[i, -1]\n",
    "        X_test = X_test.reshape(X_test.shape[0], 1, 1)\n",
    "        #print(X_test)\n",
    "        \n",
    "        single_fc = model.predict([X_test], batch_size = 1)\n",
    "        #print(single_fc)\n",
    "        test_fcs = np.append(test_fcs, single_fc[0][0])\n",
    "        \n",
    "        X_train = np.vstack((X_train, X_test))\n",
    "        y_train = np.append(y_train, y_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(f'X_train: {X_train}')\n",
    "        #print(f'y_train: {y_train}')\n",
    "    \n",
    "    test_fcs = np.ravel(min_max_scaler.inverse_transform(test_fcs.reshape(-1 ,1)))\n",
    "    y_test = test[:, -1]\n",
    "    y_test = np.ravel(min_max_scaler.inverse_transform(y_test.reshape(-1, 1)))\n",
    "    \n",
    "    test_rmse = np.round((mean_squared_error(test_fcs, y_test))**0.5, 4)\n",
    "    test_mape = np.round(get_mape(test_fcs, y_test), 4)\n",
    "    print(f'test rmse: {test_rmse}')\n",
    "    print(f'test mape: {test_mape}')\n",
    "    \n",
    "    #plt.plot(y_test)\n",
    "    #plt.plot(test_fcs)\n",
    "    #plt.show()\n",
    "    forecasts_rmse_list = []\n",
    "    forecasts_mape_list = []\n",
    "    for fcs in fcs_nr_list:\n",
    "        X_fc, y_fc = forecasts[0:fcs, 0:-1], forecasts[:fcs,-1]\n",
    "        X_fc = X_fc.reshape(X_fc.shape[0], 1, X_fc.shape[1])\n",
    "        fc_predictions = model.predict(X_fc, batch_size = 1)\n",
    "        \n",
    "        fc_predictions =   np.ravel(min_max_scaler.inverse_transform(fc_predictions))\n",
    "        y_fc = np.ravel(min_max_scaler.inverse_transform(y_fc.reshape(-1, 1)))\n",
    "        \n",
    "        fc_rmse = np.round(mean_squared_error(fc_predictions, y_fc)**0.5, 4)\n",
    "        fc_mape = np.round(get_mape(fc_predictions, y_fc), 4)\n",
    "        print(fc_rmse, fc_mape)\n",
    "        forecasts_rmse_list.append(fc_rmse)\n",
    "        forecasts_mape_list.append(fc_mape)\n",
    "    print(f'forecast rmse: {fc_rmse_list}')\n",
    "    print(f'forecast smape: {fc_mape_list}')\n",
    "    \n",
    "    return train_rmse, train_mape, test_rmse, test_mape, forecasts_rmse_list, forecasts_mape_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cv(filepath, train_rmse, train_mape, test_rmse, test_mape, fc_rmse, fc_mape):\n",
    "    \n",
    "    df = pd.DataFrame({'Data': name_list, 'Train RMSE': train_rmse,'Train MAPE': train_mape,\n",
    "                       'Test RMSE': test_rmse, 'Test MAPE': test_mape, '1-step RMSE': [x[0] for x in fc_rmse],\n",
    "                       '3-step RMSE': [x[1] for x in fc_rmse], '5-step RMSE': [x[2] for x in fc_rmse],\n",
    "                        '10-step RMSE': [x[3] for x in fc_rmse],'1-step MAPE': [x[0] for x in fc_mape],\n",
    "                       '3-step MAPE': [x[1] for x in fc_mape],'5-step MAPE': [x[2] for x in fc_mape],\n",
    "                       '10-step MAPE': [x[3] for x in fc_mape] })\n",
    "    df.to_csv(filepath, index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_list, train_mape_list, test_rmse_list, test_mape_list, fc_rmse_list, fc_mape_list = [], [], [], [], [], []\n",
    "nr_of_forecasts = [1, 3, 5, 10]\n",
    "for df in dfs_list:\n",
    "    print(df.name)\n",
    "    train_rmse, train_mape, test_rmse, test_mape, fc_rmse, fc_mape = get_accuracy(df, 0.75, fcs_nr_list= nr_of_forecasts)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    train_mape_list.append(train_mape)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    test_mape_list.append(test_mape)\n",
    "    fc_rmse_list.append(fc_rmse)\n",
    "    fc_mape_list.append(fc_mape)\n",
    "results = save_cv(\"results/LSTM_results.csv\", train_rmse_list, train_mape_list, test_rmse_list, test_mape_list, fc_rmse_list, fc_mape_list)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd0b1d608bd0e5024644dae2cdbcee13271296bd49f5e48df2e59ce3d0ae5b90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
